# Project Samarth â€” Simple Guide for Students ğŸ“ğŸšœğŸŒ§ï¸

Hello! This README explains the project in easy words. It is written for students and beginners. I use small steps, clear language, and emojis to make it friendly. ğŸ˜Š

This project is a small Streamlit app that helps you compare agriculture (crop production) and climate (rainfall) data. It can also make short data-based policy points (simple arguments) with sources (provenance). ğŸ“ŠğŸ§¾

## Table of contents

- What this project does âœ…
- What files are here ğŸ“
- How to run the app (step-by-step) â–¶ï¸
- Quick demo steps (2 minutes) â±ï¸
- Data and where it comes from ğŸ“‚
- How the outputs work (provenance) ğŸ”
- What you can change or try next âœ¨
- Troubleshooting & tips ğŸ› ï¸

---

## What this project does (short) ğŸ§¾

- Lets you load crop production and rainfall data.

- Lets you run four small question templates:

  1. Compare average rainfall and top crops between two states. ğŸŒ§ï¸ vs ğŸŒ¾
  1. Find which district has the highest or lowest production for a crop. ğŸ“
  1. Show a trend for a crop and its correlation with rainfall. ğŸ“ˆ
  1. Generate short policy-style arguments to promote one crop over another (data-backed). ğŸ—’ï¸

All outputs show simple provenance: which CSV file or resource the numbers came from, and which years were used. This helps you check the evidence. âœ…

---

## Whatâ€™s in this repository (important files) ğŸ“

- `run_app.py` â€” the main Streamlit app. Run this to open the web UI. ğŸŒ
- `qa_engine.py` â€” the code that implements the four question templates. This is where the analysis happens. ğŸ”¬
- `generator.py` â€” simple code that builds short policy arguments from evidence. âœï¸
- `normalization.py` / `schema_mapper.py` â€” helpers that clean and map messy tables into a consistent format. ğŸ§¹
- `data/` â€” sample CSV files used for demos. Use these for reproducible results. ğŸ—‚ï¸
- `requirements.txt` â€” Python dependencies to install. ğŸ“¦

---

## Simple step-by-step: Run the app locally (macOS / Linux / zsh) ğŸ–¥ï¸

1. Open a terminal in this project folder.

1. Create and activate a virtual environment (one-time setup):

```bash
python3 -m venv .venv
source .venv/bin/activate
```

1. Install Python packages:

```bash
pip install -r requirements.txt
```

1. Start the Streamlit app:

```bash
streamlit run run_app.py
```

1. The app opens in a browser. If it does not open automatically, go to `http://localhost:8501` in your browser. ğŸ•¸ï¸

**Tip:** If you use a different Python command, replace `python3` with your Python executable. âš ï¸

---

## Quick demo (2 minutes) â€” what to click â˜ï¸

1. In the app sidebar, use the Dataset Discovery area. If you have no live API access, click the demo buttons to load the sample CSVs from `data/`. ğŸ—„ï¸

1. Pick the template "Compare rainfall & top crops". Enter two states (for example: `Tamil Nadu` and `Karnataka`) and click Run. You will see average rainfall numbers and the top crops by production. ğŸŒ§ï¸â¡ï¸ğŸŒ¾

1. Try the district extremes template to see which district has the max or min production for a crop. ğŸ“

1. Try the policy-argument template (promote Crop A vs Crop B). The app will show short arguments and a provenance block listing the data sources used. ğŸ§¾âœ¨

---

## Where the data comes from (short) ğŸ“¦

- The app works with two kinds of data: crop production and rainfall. Sample CSVs live in the `data/` folder so you can always run the app without internet. ğŸŒâŒ

- The app can also search CKAN-style data catalogs and attempt to download CSV, Excel or JSON resources if you configure a catalog API key. This is optional. ğŸ”

**Important:** For reproducible demos we included small normalized CSVs in `data/` so you will get the same results shown in examples. ğŸ“‚âœ…

---

## What "provenance" means here (simple) ğŸ”

- When the app shows a number (for example, average rainfall = 500 mm), it also shows where it got that number: the filename and the years used. This is the provenance. You can open the CSV and see the same rows used in the calculation. ğŸ§¾ğŸ”—

**Why this helps:** It makes the results checkable. Anyone can look at the CSVs and verify the math. âœ…

---

## Good student-level examples (try these) ğŸ§ª

- Compare rainfall and top crops: `Tamil Nadu` vs `Karnataka` (years = 2). See rainfall difference and top 3 crops. ğŸ§¾
- District extremes: Find the district with highest Rice production in `Tamil Nadu`. ğŸ“
- Trend & correlation: Ask for `Rice` in `Karnataka` for the last 10 years and see if production tracks rainfall. ğŸ“ˆğŸŒ§ï¸
- Policy arguments: Promote `Wheat` over `Rice` in a chosen state and read the 3 short data-backed points. ğŸ“

---

## How to read the outputs (simple) ğŸ“˜

- Each result page has three parts:

  1. Numbers and charts (if any). ğŸ“Š
  1. Short explanation text. âœï¸
  1. Provenance block listing data files, years, and sample rows used as evidence. ğŸ”—

If something looks wrong, open the CSV in `data/` and inspect the rows used by the provenance. âœ…

---

## Things you can try to improve the app (projects for learning) ğŸ› ï¸

- Add more datasets: place new normalized CSVs in `data/` and update the code to recognize them. â•
- Add row-level links in the provenance block (show exact CSV row numbers). ğŸ”¢
- Add unit tests (pytest) for the four templates (`qa_engine.py`). âœ…
- Improve the policy-argument wording or scoring in `generator.py`. âœï¸

---

## Troubleshooting & common questions â“

- **Q:** The app shows blank or missing values.

  **A:** Check `data/` CSVs; some values may be missing or non-numeric. Try cleaning the CSV or use the sample CSV that ships with the repo. ğŸ§¹

- **Q:** The app does not open at `localhost:8501`.

  **A:** Confirm Streamlit started successfully in the terminal. If not, check for errors there. ğŸ”

- **Q:** I want to use live data from a catalog.

  **A:** Add catalog credentials to `.env` (if supported) and use the Dataset Discovery tools in the sidebar. This is advanced â€” start with the local CSVs first. ğŸŒ±

---

## Short glossary (easy words) ğŸ“š

- **Provenance:** the source of a number (filename, years, sample rows). ğŸ”—
- **Normalized CSV:** a CSV with columns arranged in a standard way so the code can read it easily. ğŸ“‘
- **CKAN:** a common data-catalog format. You only need it if you want to fetch live data. ğŸŒ

---

## Want to extend this for a school project? ğŸ“

1. Fork this repo on GitHub.
2. Add a new CSV in `data/` and write a small script to load and test it.
3. Add a simple unit test that checks one QA function returns expected values for your CSV.

---

Thanks for trying Project Samarth! If you want, I can also:

- add a short set of unit tests for the templates, or
- create a one-page lab exercise with step-by-step student tasks.

Have fun learning! ğŸ‰ğŸšœğŸ“ˆ



---

## Challenge status â€” what is done and what remains ğŸ§­

Below is a short, student-friendly summary of the current project state compared to the original challenge goals.

- Done âœ…

  - A reproducible Streamlit demo app (`run_app.py`) that loads normalized CSVs from `data/` and answers four template questions with simple provenance. ğŸŒ
  - Four implemented question templates in `qa_engine.py` and a policy-argument builder in `generator.py`. These were smoke-tested locally. ğŸ”¬
  - Normalization helpers (`normalization.py`, `schema_mapper.py`) to turn messy tables into the canonical CSV shape used by the app. ğŸ§¹
  - Included small normalized CSV examples in `data/` so the app runs without internet. ğŸ“‚
  - A clean Git history: the repository was reinitialized and pushed with a single commit for a tidy starting point. ğŸ§¾
  - Deployment guidance (`DEPLOY_TO_STREAMLIT.md`) and an example secrets file (`.streamlit/secrets.example.toml`) to help publish on Streamlit Community Cloud. ğŸš€

- Remaining / Future work â³

  - Live data ingestion: programmatic discovery and robust fetching from data.gov.in/CKAN catalogs (IMD and agriculture resources). This needs rate-limit handling and retry logic. ğŸŒğŸ”
  - Wider schema coverage: more mapping rules to handle diverse real-world table shapes and coded values (units, state/district name variants). ğŸ—ºï¸
  - Station metadata registry: authoritative mapping for weather station â†’ administrative region to improve rainfall aggregation accuracy. ğŸ“¡â¡ï¸ğŸ“
  - Row-level provenance: link results back to exact resource URLs and CSV row numbers so each claim is auditable. ğŸ”—ğŸ”¢
  - Better question parsing: a lightweight NLP router to map free-text questions to the correct template and extract parameters. ğŸ¤–ğŸ§ 
  - Unit tests & CI: add pytest tests for the templates and a GitHub Actions workflow to run the smoke script on every push. âœ…
  - Final deliverables: polish conversational UI, make a 2-minute demo video, and prepare the final submission package. ğŸ¬ğŸ“¦

If you want, I can now (pick one):

- implement the live CKAN ingestion plumbing first (longer work), or
- add a small CI workflow and unit tests (quick win), or
- finish by committing this README change and pushing it to the GitHub repo now (I will do this next if you confirm).


